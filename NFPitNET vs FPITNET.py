# -*- coding: utf-8 -*-
"""Non-Functioning PitNET vs Functioning PitNET (Axial) Segmented AI clivus change models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m3km1XBU7reJEKcOQBqMDNg3MEAw_hmg
"""

!pip install --quiet git+https://github.com/jacobgil/pytorch-grad-cam.git

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, random_split
from torchvision import datasets, transforms, models
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
from google.colab import drive

import os
import torch
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from collections import Counter
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import numpy as np
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/MLClivusProject/CompleteDataset/Tumors/Axial'
#may replace with coronal/sagittal images

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

full_dataset = datasets.ImageFolder(data_dir, transform=transform)
class_names = full_dataset.classes  # ['FPitNets', 'NFPitNets']
targets = [label for _, label in full_dataset]

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, 2)
model = model.to(device)

train_idx, val_idx = next(StratifiedKFold(n_splits=3, shuffle=True, random_state=42).split(np.zeros(len(targets)), targets))
train_dataset = Subset(full_dataset, train_idx)
val_dataset = Subset(full_dataset, val_idx)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

model = models.resnet18(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, 2)
model = model.to(device)

class_weights = torch.tensor([1.0, 1.0], dtype=torch.float).to(device)
criterion = nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

for epoch in range(5):
    model.train()
    running_loss, correct = 0.0, 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        correct += (outputs.argmax(1) == labels).sum().item()
    print(f"Epoch {epoch+1}: Loss = {running_loss/len(train_loader):.4f}, Acc = {correct/len(train_loader.dataset):.4f}")

model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        preds = outputs.argmax(1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
print(classification_report(all_labels, all_preds, target_names=class_names))
sns.heatmap(confusion_matrix(all_labels, all_preds), annot=True, xticklabels=class_names, yticklabels=class_names, fmt='d')
plt.xlabel("Predicted"); plt.ylabel("Actual"); plt.title("Confusion Matrix"); plt.show()

cam = GradCAM(model=model, target_layers=[model.layer4[-1]])

def generate_gradcam(img_tensor, true_label):
    input_tensor = img_tensor.unsqueeze(0).to(device)
    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(true_label)])[0]
    input_image = img_tensor.permute(1, 2, 0).cpu().numpy()
    input_image = (input_image * 0.5) + 0.5
    return show_cam_on_image(input_image, grayscale_cam, use_rgb=True)

FPitNets_samples = random.sample([s for s in val_dataset if s[1] == 0], 5)
NFPitNets_samples = random.sample([s for s in val_dataset if s[1] == 1], 5)
fig, axes = plt.subplots(2, 5, figsize=(20, 8))

for i in range(5):
    for row, (samples, label_name) in enumerate(zip([FPitNets_samples, NFPitNets_samples], ['FPitNets', 'NFPitNets'])):
        img_tensor, label = samples[i]
        cam_image = generate_gradcam(img_tensor, label)
        axes[row][i].imshow(cam_image)
        axes[row][i].set_title(f"{label_name}")
        axes[row][i].axis('off')

plt.suptitle("Grad-CAM: FPitNets (Top) vs NFPitNets (Bottom)", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

from sklearn.metrics import roc_curve, auc, RocCurveDisplay

model.eval()
y_true = []
y_probs = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        probs = torch.softmax(outputs, dim=1)[:, 1]
        y_probs.extend(probs.cpu().numpy())
        y_true.extend(labels.cpu().numpy())

fpr, tpr, thresholds = roc_curve(y_true, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([-0.02, 1.0])
plt.ylim([0.0, 1.02])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - FPitNets vs NFPitNets')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

full_dataset = datasets.ImageFolder(data_dir)

from torchvision.datasets.folder import default_loader

class CustomImageDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform):
        self.dataset = dataset
        self.indices = indices
        self.transform = transform
        self.loader = default_loader

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        path, label = self.dataset.samples[self.indices[idx]]
        image = self.loader(path)
        if self.transform:
            image = self.transform(image)
        return image, label

train_idx, val_idx = next(StratifiedKFold(n_splits=3, shuffle=True, random_state=42).split(np.zeros(len(targets)), targets))
train_dataset = CustomImageDataset(full_dataset, train_idx, transform=train_transform)
val_dataset = CustomImageDataset(full_dataset, val_idx, transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)



from sklearn.metrics import classification_report, confusion_matrix

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        preds = outputs.argmax(1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))

conf_mat = confusion_matrix(all_labels, all_preds)
sns.heatmap(conf_mat, annot=True, xticklabels=class_names, yticklabels=class_names, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import roc_curve, auc

model.eval()
y_true, y_probs = [], []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        probs = torch.softmax(outputs, dim=1)[:, 1]
        y_probs.extend(probs.cpu().numpy())
        y_true.extend(labels.cpu().numpy())

fpr, tpr, _ = roc_curve(y_true, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

target_layers = [model.layer4[-1]]
cam = GradCAM(model=model, target_layers=target_layers)

def generate_gradcam(img_tensor, pred_label):
    input_tensor = img_tensor.unsqueeze(0).to(device)

    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_label)])[0]

    input_image = img_tensor.permute(1, 2, 0).cpu().numpy()
    input_image = (input_image * 0.5) + 0.5
    return show_cam_on_image(input_image, grayscale_cam, use_rgb=True)

FPitNets_samples = random.sample([s for s in val_dataset if s[1] == 0], 5)
NFPitNets_samples = random.sample([s for s in val_dataset if s[1] == 1], 5)

fig, axes = plt.subplots(2, 5, figsize=(20, 8))

for i in range(5):
    for row, (samples, label_name) in enumerate(zip([FPitNets_samples, NFPitNets_samples], ['FPitNets', 'NFPitNets'])):
        img_tensor, true_label = samples[i]

        model.eval()
        with torch.no_grad():
            input_tensor = img_tensor.unsqueeze(0).to(device)
            output = model(input_tensor)
            pred_label = torch.argmax(F.softmax(output, dim=1), dim=1).item()
            confidence = F.softmax(output, dim=1)[0, pred_label].item()

        cam_image = generate_gradcam(img_tensor, pred_label)

        ax = axes[row][i]
        ax.imshow(cam_image)
        ax.set_title(f"True: {class_names[true_label]}\nPred: {class_names[pred_label]} ({confidence:.2f})", fontsize=10)
        ax.axis('off')

plt.suptitle("Grad-CAM Evaluation After Augmentation\nTop: FPitNets, Bottom: NFPitNets", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image

target_layers = [model.layer4[-1]]
cam = GradCAM(model=model, target_layers=target_layers)

def generate_gradcam(img_tensor, pred_label):
    input_tensor = img_tensor.unsqueeze(0).to(device)
    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_label)])[0]
    input_image = img_tensor.permute(1, 2, 0).cpu().numpy()
    input_image = (input_image * 0.5) + 0.5
    return show_cam_on_image(input_image, grayscale_cam, use_rgb=True)

results = []

model.eval()
with torch.no_grad():
    for img_tensor, true_label in val_dataset:
        input_tensor = img_tensor.unsqueeze(0).to(device)
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)[0]
        pred_label = torch.argmax(probs).item()
        confidence = probs[pred_label].item()
        correct = (pred_label == true_label)
        results.append((img_tensor, true_label, pred_label, confidence, correct))

def plot_gradcam_grid(results, title, n=5):
    samples = results[:n]
    fig, axes = plt.subplots(1, len(samples), figsize=(4 * n, 4))
    if len(samples) == 1:
        axes = [axes]

    for i, (img_tensor, true_label, pred_label, confidence, _) in enumerate(samples):
        cam_img = generate_gradcam(img_tensor, pred_label)
        axes[i].imshow(cam_img)
        axes[i].set_title(f"True: {class_names[true_label]}\nPred: {class_names[pred_label]} ({confidence:.2f})")
        axes[i].axis('off')

    plt.suptitle(title, fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.93])
    plt.show()

correct_preds = [r for r in results if r[-1] == True]
incorrect_preds = [r for r in results if r[-1] == False]

correct_preds.sort(key=lambda x: x[3], reverse=True)
incorrect_preds.sort(key=lambda x: x[3], reverse=True)

plot_gradcam_grid(correct_preds, title="Grad-CAM: Correct Predictions", n=5)
plot_gradcam_grid(incorrect_preds, title="Grad-CAM: Incorrect Predictions", n=5)

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
target_layers = [model.layer4[-1]]
cam = GradCAM(model=model, target_layers=target_layers)

def generate_gradcam(img_tensor, pred_label):
    input_tensor = img_tensor.unsqueeze(0).to(device)
    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_label)])[0]
    input_image = img_tensor.permute(1, 2, 0).cpu().numpy()
    input_image = (input_image * 0.5) + 0.5
    return show_cam_on_image(input_image, grayscale_cam, use_rgb=True)
false_negatives = []

model.eval()
with torch.no_grad():
    for img_tensor, true_label in val_dataset:
        input_tensor = img_tensor.unsqueeze(0).to(device)
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)[0]
        pred_label = torch.argmax(probs).item()
        confidence = probs[pred_label].item()

        if true_label == 1 and pred_label == 0:
            false_negatives.append((img_tensor, true_label, pred_label, confidence))
def plot_false_negatives_grid(fn_results, n=5):
    samples = fn_results[:n]
    fig, axes = plt.subplots(1, len(samples), figsize=(4 * n, 4))
    if len(samples) == 1:
        axes = [axes]

    for i, (img_tensor, true_label, pred_label, confidence) in enumerate(samples):
        cam_img = generate_gradcam(img_tensor, pred_label)
        axes[i].imshow(cam_img)
        axes[i].set_title(f"FN: True=FPitNets, Pred=NFPitNets ({confidence:.2f})", fontsize=10)
        axes[i].axis('off')

    plt.suptitle("Grad-CAM: False Negatives (Missed Tumors)", fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.93])
    plt.show()

false_negatives.sort(key=lambda x: x[3], reverse=True)

plot_false_negatives_grid(false_negatives, n=min(5, len(false_negatives)))

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, random_split
from torchvision import datasets, transforms, models
from torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
from google.colab import drive

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

full_dataset = datasets.ImageFolder(data_dir)
class_names = full_dataset.classes

def default_loader(path):
    from PIL import Image
    return Image.open(path).convert('RGB')

class CustomImageDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform):
        self.samples = [dataset.samples[i] for i in indices]
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        image = default_loader(path)
        image = self.transform(image)
        return image, label

targets = [label for _, label in full_dataset.samples]
train_idx, val_idx = next(StratifiedKFold(n_splits=3, shuffle=True, random_state=42).split(np.zeros(len(targets)), targets))
train_dataset = CustomImageDataset(full_dataset, train_idx, transform=train_transform)
val_dataset = CustomImageDataset(full_dataset, val_idx, transform=val_transform)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

def create_vit_model():
    weights = ViT_B_16_Weights.DEFAULT
    model = vit_b_16(weights=weights)
    model.heads.head = nn.Linear(model.heads.head.in_features, 2)
    return model.to(device)

model = create_vit_model()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.CrossEntropyLoss()

for epoch in range(5):
    model.train()
    running_loss = 0.0
    correct = 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        correct += (outputs.argmax(1) == labels).sum().item()
    print(f"Epoch {epoch+1}: Loss = {running_loss / len(train_loader):.4f}, Acc = {correct / len(train_loader.dataset):.4f}")

model.eval()
all_preds = []
all_labels = []
with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        preds = outputs.argmax(1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))
conf_mat = confusion_matrix(all_labels, all_preds)
sns.heatmap(conf_mat, annot=True, xticklabels=class_names, yticklabels=class_names, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

model.eval()
y_true = []
y_probs = []
with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        probs = F.softmax(outputs, dim=1)[:, 1]
        y_probs.extend(probs.cpu().numpy())
        y_true.extend(labels.cpu().numpy())
fpr, tpr, _ = roc_curve(y_true, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()

from pytorch_grad_cam.utils.image import show_cam_on_image

def reshape_transform(tensor, height=14, width=14):
    result = tensor[:, 1:, :].reshape(tensor.size(0), height, width, -1)
    result = result.permute(0, 3, 1, 2)
    return result

def generate_vit_gradcam(model, img_tensor, pred_label):
    input_tensor = img_tensor.unsqueeze(0).to(device)
    target_layers = [model.encoder.layers[-1].ln_1]
    cam = GradCAM(model=model, target_layers=target_layers, reshape_transform=reshape_transform)
    grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(pred_label)])[0]
    input_image = img_tensor.permute(1, 2, 0).cpu().numpy()
    input_image = (input_image * 0.5) + 0.5
    return show_cam_on_image(input_image, grayscale_cam, use_rgb=True)

gradcam_results = []
sample_count = 0
max_samples = 6
for inputs, labels in val_loader:
    for i in range(inputs.size(0)):
        if sample_count >= max_samples:
            break
        img_tensor = inputs[i]
        label = labels[i].item()
        input_tensor = img_tensor.unsqueeze(0).to(device)
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)[0]
        pred_label = torch.argmax(probs).item()
        confidence = probs[pred_label].item()
        cam_image = generate_vit_gradcam(model, img_tensor, pred_label)
        gradcam_results.append((cam_image, label, pred_label, confidence))
        sample_count += 1
    if sample_count >= max_samples:
        break
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
for i, (cam_img, true_label, pred_label, conf) in enumerate(gradcam_results):
    ax = axes[i // 3][i % 3]
    ax.imshow(cam_img)
    ax.set_title(f"True: {class_names[true_label]}\nPred: {class_names[pred_label]} ({conf:.2f})")
    ax.axis('off')
plt.suptitle("ViT Grad-CAM (CT Skull)", fontsize=18)
plt.tight_layout()
plt.show()

